{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60bf104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact same setup as before, except we don't need the mutations, just the tree itself\n",
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "Ne_anc = 1e4\n",
    "Ne = [1e4, 1e4]\n",
    "m = [0.0001]\n",
    "tau = 1000.0\n",
    "demo = msp.Demography()\n",
    "demo.add_population(initial_size= Ne_anc, name = \"anc\")\n",
    "demo.add_population(initial_size = Ne[0], name = \"P0\")\n",
    "demo.add_population(initial_size = Ne[1], name = \"P1\")\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate= m[0])\n",
    "tmp = [f\"P{i}\" for i in range(2)]\n",
    "demo.add_population_split(time = tau, derived=tmp, ancestral=\"anc\")\n",
    "g = demo.to_demes()\n",
    "# demesdraw.tubes(g)\n",
    "# print(g)\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f24994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Matrix exponential using uniformization method\"\n",
    "\n",
    "from beartype import beartype\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.stats import poisson\n",
    "import equinox as eqx\n",
    "from beartype.typing import Callable\n",
    "from jaxtyping import Float, Array, ArrayLike, ScalarLike\n",
    "\n",
    "\n",
    "@beartype\n",
    "def expm_unif(\n",
    "    t: ScalarLike,\n",
    "    A: Callable[[Float[ArrayLike, \"*shape\"]], Float[ArrayLike, \"*shape\"]],\n",
    "    v: Float[ArrayLike, \"*shape\"],\n",
    "    alpha: ScalarLike,\n",
    "    eps: float = 1e-6,\n",
    ") -> Float[Array, \"*shape\"]:\n",
    "    \"\"\"Compute matrix exponential via uniformization.\n",
    "\n",
    "    Args:\n",
    "        t: Time scalar.\n",
    "        A: Function that computes action A @ v, where A is an intensity matrix.\n",
    "        alpha: max(abs(diag(A)))\n",
    "        eps: Tolerance for the uniformization method.\n",
    "\n",
    "    Returns:\n",
    "        expm(t*A) @ v: Matrix exponential applied to vector v.\n",
    "\n",
    "    Notes:\n",
    "        This implements Algorithm 1 of \"INEXACT UNIFORMIZATION METHOD FOR COMPUTING\n",
    "        TRANSIENT DISTRIBUTIONS OF MARKOV CHAINS\", Sidje et al., SIAM J. Sci. Comput.,\n",
    "        2007.\n",
    "    \"\"\"\n",
    "\n",
    "    def P(v):\n",
    "        return v + A(v) / alpha\n",
    "\n",
    "    THETA = 100.0\n",
    "    m = jnp.ceil(alpha * t / THETA).astype(int)\n",
    "    t = t / m\n",
    "    s = alpha * t\n",
    "    r = jnp.exp(-s)\n",
    "\n",
    "    ell = eqx.internal.while_loop(\n",
    "        lambda ell: poisson.cdf(ell, alpha * t) < 1 - eps,\n",
    "        lambda ell: ell + 1,\n",
    "        0,\n",
    "        kind=\"checkpointed\",\n",
    "        checkpoints=10,\n",
    "    )\n",
    "\n",
    "    def body2(tup):\n",
    "        k, w, f = tup\n",
    "        f = (s / k) * P(f)\n",
    "        w = w + f\n",
    "        return (k + 1, w, f)\n",
    "\n",
    "    def body1(tup):\n",
    "        i, w = tup\n",
    "        _, w, _ = eqx.internal.while_loop(\n",
    "            lambda tup: tup[0] <= ell,\n",
    "            body2,\n",
    "            (1, w, w),\n",
    "            kind=\"checkpointed\",\n",
    "            checkpoints=10,\n",
    "        )\n",
    "        return (i + 1, w * r)\n",
    "\n",
    "    _, w = eqx.internal.while_loop(\n",
    "        lambda tup: tup[0] <= m,\n",
    "        body1,\n",
    "        (1, v),\n",
    "        kind=\"checkpointed\",\n",
    "        checkpoints=10,\n",
    "    )\n",
    "\n",
    "    return w\n",
    "\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import interpax\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import Array, ArrayLike, Float, Scalar, ScalarLike\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class CoalRate(ABC):\n",
    "    @abstractproperty\n",
    "    def jumps(self) -> Float[Array, \"_\"]:\n",
    "        \"\"\"Return the times at which the coalescent rate changes discontinuously.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: ScalarLike) -> Scalar:\n",
    "        \"\"\"Evaluate the coalescent rate at time t.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def R(self, a: ScalarLike, b: ScalarLike) -> Scalar:\n",
    "        r\"\"\"Integrated coalescent rate,\n",
    "\n",
    "        int_a^b self(t) dt\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class PiecewiseConstant(CoalRate):\n",
    "    \"\"\"Piecewise constant coalescent rate.\"\"\"\n",
    "\n",
    "    c: Float[ArrayLike, \"T\"]\n",
    "    t: Float[ArrayLike, \"T\"]\n",
    "\n",
    "    @property\n",
    "    def jumps(self) -> Float[Array, \"T\"]:\n",
    "        \"\"\"Return the times at which the coalescent rate changes discontinuously.\"\"\"\n",
    "        return jnp.array(self.t)\n",
    "\n",
    "    @property\n",
    "    def _ppoly(self) -> interpax.PPoly:\n",
    "        return interpax.PPoly(self.c[None], jnp.append(self.t, jnp.inf), check=False)\n",
    "\n",
    "    def __call__(self, t: ScalarLike) -> Scalar:\n",
    "        return self._ppoly(t)\n",
    "\n",
    "    def R(self, a: ScalarLike, b: ScalarLike) -> Scalar:\n",
    "        return self._ppoly.integrate(a, b)\n",
    "\n",
    "\"Likelihood of an ARG\"\n",
    "\n",
    "import diffrax as dfx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap\n",
    "from jax.scipy.special import xlog1py, xlogy\n",
    "from jaxtyping import Array, Float, Scalar, ScalarLike\n",
    "\n",
    "def loglik(eta: CoalRate, r: ScalarLike, data: Float[Array, \"intervals 2\"]) -> Scalar:\n",
    "    \"\"\"Compute the log-likelihood of the data given the demographic model.\n",
    "\n",
    "    Args:\n",
    "        eta: Coalescent rate at time t.\n",
    "        r: float, the recombination rate.\n",
    "        data: the data to compute the likelihood for. The first column is the TMRCA, and\n",
    "              the second column is the span.\n",
    "\n",
    "    Notes:\n",
    "        - Successive spans that have the same TMRCA should be merged into one span:\n",
    "          <tmrca, span1> + <tmrca, span1> = <tmrca, span + span>.\n",
    "        - Missing data/padding indicated by span<=0.\n",
    "    \"\"\"\n",
    "    times, spans = data.T\n",
    "    i = times.argsort()\n",
    "    sorted_times = times[i]\n",
    "\n",
    "    def f(t, y, _):\n",
    "        c = eta(t)\n",
    "        A = jnp.array([[-r, r, 0.0], [c, -2 * c, c], [0.0, 0.0, 0.0]])\n",
    "        return A.T @ y\n",
    "\n",
    "    y0 = jnp.array([1.0, 0.0, 0.0])\n",
    "    solver = dfx.Tsit5()\n",
    "    term = dfx.ODETerm(f)\n",
    "    ssc = dfx.PIDController(rtol=1e-6, atol=1e-6, jump_ts=eta.jumps)\n",
    "    T = times.max()\n",
    "    sol = dfx.diffeqsolve(\n",
    "        term,\n",
    "        solver,\n",
    "        0.0,\n",
    "        T,\n",
    "        dt0=0.001,\n",
    "        y0=y0,\n",
    "        stepsize_controller=ssc,\n",
    "        saveat=dfx.SaveAt(ts=sorted_times),\n",
    "    )\n",
    "\n",
    "    # invert the sorting so that cscs matches times\n",
    "    i_inv = i.argsort()\n",
    "    cscs = sol.ys[i_inv]\n",
    "\n",
    "    @vmap\n",
    "    def p(t0, csc0, t1, csc1, span):\n",
    "        p_nr_t0, p_float_t0, p_coal_t0 = csc0\n",
    "        p_nr_t1, p_float_t1, p_coal_t1 = csc1\n",
    "        # no recomb for first span - 1 positions\n",
    "        r1 = xlogy(span - 1, p_nr_t0)\n",
    "        # coalescence at t1\n",
    "        r2 = jnp.log(eta(t1))\n",
    "        # back-coalescence process up to t1, depends to t0 >< t1\n",
    "        r3 = jnp.where(\n",
    "            t0 < t1, jnp.log(p_float_t0) - eta.R(t0, t1), jnp.log(p_float_t1)\n",
    "        )\n",
    "        return r1 + r2 + r3\n",
    "\n",
    "    ll = p(times[:-1], cscs[:-1], times[1:], cscs[1:], spans[:-1]).sum()\n",
    "    # for the last position, we only know span was at least as long\n",
    "    ll += xlogy(spans[-1], cscs[-1, 0])\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80006ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkliang/opt/Demes/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.experimental.sparse as jesp\n",
    "import scipy.sparse as sp\n",
    "from jax.experimental import sparse\n",
    "from jax.experimental.sparse import BCOO\n",
    "from jax import lax\n",
    "import scipy\n",
    "from jax import vmap\n",
    "import phlash\n",
    "from phlash.likelihood.arg import log_density\n",
    "\n",
    "\n",
    "def _matvec(params, y):\n",
    "    Q, Q1, q = params\n",
    "    n = q.shape[0]\n",
    "    yn = y[:-1].reshape(n, n)\n",
    "    yd = jnp.diag(yn)\n",
    "    ret = Q @ yn + yn @ Q\n",
    "    ret -= Q1 * yn\n",
    "    ret -= jnp.diag(q * yd)\n",
    "    return jnp.append(ret.reshape(n ** 2), q.dot(yd))\n",
    "\n",
    "def unit_vector(size, index):\n",
    "    # Vector of zeros\n",
    "    tmp = jnp.zeros(size)\n",
    "    # ith element will be 1\n",
    "    # JAX arrays are immutable so we cannot do tmp[index] = 1\n",
    "    tmp = tmp.at[index].set(1)\n",
    "    return tmp\n",
    "\n",
    "# Instead using a coalesce rate c like migration_process jupyter notebook we use q\n",
    "def solve_ode(time_discretization, init_vertices, q, m, BCOO_indices, index, tau):\n",
    "    # edges is 0 ONLY IF you have a graph with only a SINGLE node\n",
    "    num_nodes = len(q)\n",
    "    shape = (num_nodes, num_nodes)\n",
    "    if len(m) == 0:\n",
    "        # If the graph has absolutely no edges then the graph has 0 for every edge weight\n",
    "        # in the way we code Q.\n",
    "        copy = jesp.BCOO(((jnp.array([], dtype=jnp.float32), jnp.empty((0, len(shape)), dtype=jnp.int32))), shape=shape)\n",
    "    else:\n",
    "        copy = jesp.BCOO((m.astype(float), BCOO_indices.astype(jnp.int64)), shape=shape)\n",
    "        \n",
    "    Q = copy + copy.transpose()\n",
    "    Q1 = Q.sum(0).todense()[:, None] + Q.sum(1).todense()[None, :]\n",
    "    e_i = unit_vector(num_nodes, init_vertices[0])\n",
    "    e_j = unit_vector(num_nodes, init_vertices[1])\n",
    "    tmp = (e_i.reshape(-1, 1)) @ jnp.array([e_j])\n",
    "    y0 = jnp.append(jnp.ravel(tmp), 0)\n",
    "    from functools import partial\n",
    "    A = partial(_matvec, (Q, Q1, q))\n",
    "    sol = vmap(expm_unif, in_axes = (0, None, None, None))(time_discretization, A, y0, 2*jnp.max(m) + jnp.max(q))\n",
    "    sol = sol[:, -1]\n",
    "    print(sol)\n",
    "    sol = jnp.insert(sol, 0, 0.0)\n",
    "    probabilities = jnp.diff(sol)\n",
    "    prob_not_coal = 1 - sol[index]\n",
    "    return probabilities, sol, prob_not_coal\n",
    "\n",
    "def from_pmf(t, p):\n",
    "    \"\"\"Initialize a size history from a distribution function of coalescent times.\n",
    "\n",
    "    Args:\n",
    "        t: time points\n",
    "        p: p[i] = probability of coalescing in [t[i], t[i + 1])\n",
    "    \"\"\"\n",
    "    sum_initial = 0.0\n",
    "    c = []\n",
    "    p = jnp.clip(p, 0, jnp.inf)\n",
    "    tol = 1e-4\n",
    "    # difference in times\n",
    "    dts = jnp.diff(t)\n",
    "    p_truncated = p[:-1]\n",
    "\n",
    "    # scan function\n",
    "    def scan_fn(carry, inputs):\n",
    "        sum_i = carry\n",
    "        dt, p_i = inputs\n",
    "        x = p_i / (1 - sum_i)\n",
    "        bad = (x >= 1) | (x <= 0) | jnp.isnan(x) | jnp.isinf(x)\n",
    "        x_safe = jnp.where(bad, 0., x)\n",
    "        c_safe = jnp.where(bad, tol, -jnp.log1p(-x_safe) / dt)\n",
    "        c_final = jnp.where(c_safe > tol, c_safe, tol)\n",
    "        sum_i = sum_i + p_i\n",
    "        return sum_i, c_final\n",
    "    \n",
    "    inputs = (dts, p_truncated)\n",
    "    sum_final, c = jax.lax.scan(scan_fn, sum_initial, inputs)\n",
    "    # Append the last coalescent rate (not identifiable from data)\n",
    "    c = jnp.append(c, c[-1])\n",
    "    return jnp.array(t), jnp.array(c)\n",
    "\n",
    "def density(m, Ne, tau, Ne_anc, BCOO_indices, init_vertices, tmrca_span): \n",
    "    t = jnp.geomspace(1e-4, jnp.max(tmrca_span[:, 0]), 1000)\n",
    "    # t = jnp.insert(jnp.geomspace(1e-4, 15.0, 1000), 0, 0.0)\n",
    "    index = jnp.searchsorted(t, tau, side = \"right\")\n",
    "    t_aug = jnp.insert(t, index, tau)\n",
    "    index = index + 1\n",
    "    probabilities, sol, p_not_coal = solve_ode(t_aug, init_vertices=init_vertices, q=1/(2*Ne), m=m, BCOO_indices=BCOO_indices, index=index, tau=tau)\n",
    "    # print(probabilities)\n",
    "    t_aug = jnp.insert(t_aug, 0, 0.0) \n",
    "    rates = jnp.diff(t_aug) * (t_aug > tau)[1:] * (1/(2*Ne_anc))\n",
    "    # rates = jnp.diff(jnp.maximum(t_aug, tau)) * q_anc\n",
    "    cum_rates = jnp.cumsum(rates)\n",
    "    # cum_rates = (t_aug - tau).clip(0)[1:] * q_anc\n",
    "    after_tau_surv_probs = jnp.exp(-cum_rates) * p_not_coal\n",
    "    after_tau_epoch_probs = jnp.abs(jnp.diff(after_tau_surv_probs))\n",
    "\n",
    "    indices = jnp.arange(len(t)+1)\n",
    "    after_tau_epoch_probs = jnp.append(after_tau_epoch_probs, 0)\n",
    "    # Define conditions\n",
    "    conditions = [\n",
    "        (indices == index-1),  \n",
    "        (indices >= index)\n",
    "    ]\n",
    "\n",
    "    # Define choices corresponding to each condition\n",
    "    choices = [\n",
    "        probabilities[index-1]+after_tau_epoch_probs[index-1],\n",
    "        after_tau_epoch_probs\n",
    "    ]\n",
    "\n",
    "    # Default case (when none of the above conditions are met, use 'a')\n",
    "    result = jnp.select(conditions, choices, default=probabilities)\n",
    "    final_probabilities = result.at[-1].set(1-jnp.sum(result))\n",
    "    # print(final_probabilities)\n",
    "    # vmap_surv_prob = 1 - np.insert(np.cumsum(final_probabilities), 0, 0)[:-1]\n",
    "    # vmap_surv_prob\n",
    "\n",
    "    t = jnp.insert(t, 0, 0.0)\n",
    "    t, c = from_pmf(t, final_probabilities)\n",
    "\n",
    "    # import phlash\n",
    "    # from phlash.likelihood.arg import log_density\n",
    "\n",
    "    # eta = phlash.size_history.SizeHistory(t=t, c=c)\n",
    "    # dm = phlash.size_history.DemographicModel(\n",
    "    #     eta=eta, theta=None, rho=1e-8\n",
    "    # )\n",
    "    eta = PiecewiseConstant(c=c, t=t)\n",
    "    log_density = loglik(eta, 1e-8, jnp.array(tmrca_span, dtype=jnp.float64))\n",
    "    \n",
    "    # return log_density(dm, tmrca_span[None])# , vmap_surv_prob, c\n",
    "    return log_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f786119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-07-22 00:22:25,655:jax._src.xla_bridge:945: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-07-22 00:22:25,657:jax._src.xla_bridge:945: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/opt/homebrew/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "def sample_tmrca_spanss(ts, subkey=jax.random.PRNGKey(1), num_pop=2):\n",
    "    samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "    sample1, sample2 = samples[0], samples[1]\n",
    "\n",
    "    pop1 = ts.node(sample1.item(0)).population - 1\n",
    "    pop2 = ts.node(sample2.item(0)).population - 1\n",
    "    sample_config = (pop1, pop2)\n",
    "\n",
    "    # Precompute all TMRCAs and spans into arrays\n",
    "    tmrcas = []\n",
    "    spans = []\n",
    "    for tree in ts.trees():\n",
    "        spans.append(tree.interval.right - tree.interval.left)\n",
    "        tmrcas.append(tree.tmrca(sample1, sample2))\n",
    "    \n",
    "    # Convert to JAX arrays\n",
    "    tmrcas = jnp.array(tmrcas)  # Shape: (num_trees,)\n",
    "    spans = jnp.array(spans)    # Shape: (num_trees,)\n",
    "    tmrcas_spans = jnp.stack([tmrcas, spans], axis=1)  # Shape: (num_trees, 2)\n",
    "\n",
    "    # Merge consecutive spans with same TMRCA\n",
    "    def merge_spans(carry, x):\n",
    "        current_tmrca, current_span, idx, output = carry\n",
    "        tmrca, span = x\n",
    "        \n",
    "        # Update each component individually\n",
    "        new_tmrca = jnp.where(tmrca == current_tmrca, current_tmrca, tmrca)\n",
    "        new_span = jnp.where(tmrca == current_tmrca, current_span + span, span)\n",
    "        new_idx = jnp.where(tmrca == current_tmrca, idx, idx + 1)\n",
    "        new_output = jnp.where(\n",
    "            tmrca == current_tmrca, \n",
    "            output, \n",
    "            output.at[idx].set(jnp.array([current_tmrca, current_span]))\n",
    "        )\n",
    "        \n",
    "        return (new_tmrca, new_span, new_idx, new_output), None\n",
    "\n",
    "    init_carry = (tmrcas_spans[0, 0], 0.0, 0, jnp.full((ts.num_trees, 2), jnp.array([1.0, 0.0])))\n",
    "    final_carry, _ = jax.lax.scan(merge_spans, init_carry, tmrcas_spans)\n",
    "    final_tmrca, final_span, _, final_output = final_carry\n",
    "    final_output = final_output.at[-1].set(jnp.array([final_tmrca, final_span]))\n",
    "    is_ones = jnp.all(final_output == jnp.array([1.0, 0.0]), axis=1)\n",
    "    reordered_arr = jnp.concatenate([final_output[~is_ones], final_output[is_ones]])\n",
    "\n",
    "    return reordered_arr, sample_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d30c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import jax.experimental.sparse as jesp\n",
    "import scipy.sparse as sp\n",
    "graph = nx.Graph()\n",
    "graph.add_edge(0, 1)\n",
    "tmp = jesp.BCOO.from_scipy_sparse(sp.triu(nx.adjacency_matrix(graph, np.arange(2)).astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcc85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float64[1001])>with<JVPTrace> with\n",
      "  primal = Traced<ShapedArray(float64[1001])>with<DynamicJaxprTrace>\n",
      "  tangent = Traced<ShapedArray(float64[1001])>with<JaxprTrace> with\n",
      "    pval = (ShapedArray(float64[1001]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x162874850>, in_tracers=(Traced<ShapedArray(float64[1001,1]):JaxprTrace>,), out_tracer_refs=[<weakref at 0x162a00d60; to 'JaxprTracer' at 0x162a011d0>], out_avals=[ShapedArray(float64[1001])], primitive=squeeze, params={'dimensions': (1,)}, effects=frozenset(), source_info=<jax._src.source_info_util.SourceInfo object at 0x1629ec610>, ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=None, xla_metadata={}))\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from functools import partial\n",
    "\n",
    "def transform_params(params):\n",
    "    m_unconstrained, q_unconstrained, tau_unconstrained, q_anc_unconstrained = params\n",
    "    # Sigmoid maps to (0, 1), then scale to (0, 2)\n",
    "    m = jax.nn.softplus(m_unconstrained)\n",
    "    q = jax.nn.softplus(q_unconstrained)\n",
    "    tau = jax.nn.softplus(tau_unconstrained)\n",
    "    q_anc = jax.nn.softplus(q_anc_unconstrained)\n",
    "    return (m, q, tau, q_anc)\n",
    "\n",
    "def inverse_transform_params(params):\n",
    "    \"\"\"Convert constrained params back to unconstrained via inverse softplus.\"\"\"\n",
    "    m, q, tau, q_anc = params\n",
    "    m_unconstrained = jnp.log(jnp.exp(m) - 1)  # Inverse softplus\n",
    "    q_unconstrained = jnp.log(jnp.exp(q) - 1)\n",
    "    tau_unconstrained = jnp.log(jnp.exp(tau) - 1)\n",
    "    q_anc_unconstrained = jnp.log(jnp.exp(q_anc) - 1)\n",
    "    return (m_unconstrained, q_unconstrained, tau_unconstrained, q_anc_unconstrained)\n",
    "\n",
    "def loss_fn(params, tmp_indices, sample_config, tmrca_span):\n",
    "    m, q, tau, q_anc = params\n",
    "    return density(m, q, tau, q_anc, tmp_indices, sample_config, tmrca_span)\n",
    "\n",
    "# 2. Initialize parameters\n",
    "def init_params(m_shape, q_shape):\n",
    "    # Initialize with reasonable values for your problem\n",
    "    m = jnp.ones(m_shape) * 0.0001  # Example initialization\n",
    "    q = jnp.ones(q_shape) * 10000\n",
    "    tau = 1000.0  # Example initial value\n",
    "    q_anc = 10000 # Example initial value\n",
    "\n",
    "    # Convert to unconstrained space for optimization\n",
    "    m_unconstrained = jnp.log(jnp.exp(m) - 1)  # Inverse softplus\n",
    "    q_unconstrained = jnp.log(jnp.exp(q) - 1)\n",
    "    tau_unconstrained = jnp.log(jnp.exp(tau) - 1)\n",
    "    q_anc_unconstrained = jnp.log(jnp.exp(q_anc) - 1)\n",
    "    \n",
    "    return (m_unconstrained, q_unconstrained, tau_unconstrained, q_anc_unconstrained)\n",
    "    # return (m, q, tau, q_anc)\n",
    "\n",
    "# 4. Set up the optimization\n",
    "def optimize(params, optimizer, tmp_indices, ts, num_steps=1000):\n",
    "    # Initialize optimizer state\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    # Initialize random key\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    \n",
    "    # Define the update step (now without ts)\n",
    "    @jax.jit\n",
    "    def step(params, opt_state, tmp_indices, sample_config, tmrca_span):\n",
    "        # Compute loss and gradients\n",
    "        params = transform_params(params)\n",
    "        jax.debug.print(\"params:{}\", params, ordered=True)\n",
    "        loss, grads = jax.value_and_grad(loss_fn)(params, tmp_indices, sample_config, tmrca_span)\n",
    "\n",
    "        # Update parameters\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        \n",
    "        return params, opt_state, loss, grads\n",
    "    \n",
    "    # Training loop\n",
    "    losses = []\n",
    "    for step_num in range(num_steps):\n",
    "        # Generate new samples outside the JIT-compiled step\n",
    "        key, subkey = jax.random.split(key)\n",
    "        tmrca_span, sample_config = sample_tmrca_spanss(ts, subkey)\n",
    "        \n",
    "        # Perform optimization step\n",
    "        params, opt_state, loss, grads = step(params, opt_state, tmp_indices, sample_config, tmrca_span)\n",
    "        print(inverse_transform_params(params))\n",
    "        # print(loss)\n",
    "        # print(grads)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if step_num % 100 == 0:  # Print progress every 100 steps\n",
    "            print(f\"Step {step_num}, Loss: {loss}\")\n",
    "    \n",
    "    return params, losses\n",
    "\n",
    "# Example usage\n",
    "# Initialize parameters\n",
    "params = init_params(m_shape=jnp.array(m).shape, q_shape=jnp.array(Ne).shape)  # Adjust shapes as needed\n",
    "\n",
    "optimizer = optax.chain(optax.clip_by_global_norm(1.0),\n",
    "                        optax.adam(learning_rate=0.1)\n",
    ")\n",
    "\n",
    "with jax.debug_nans(False), jax.disable_jit(False):\n",
    "    optimized_params_unconstrained, losses = optimize(\n",
    "        params, optimizer, tmp.indices, ts, num_steps=1000\n",
    "    )\n",
    "\n",
    "# Convert back to constrained space for final results\n",
    "optimized_params = transform_params(optimized_params_unconstrained)\n",
    "\n",
    "print(\"\\nOptimized parameters:\")\n",
    "print(f\"m: {optimized_params[0]}\")\n",
    "print(f\"q: {optimized_params[1]}\")\n",
    "print(f\"tau: {optimized_params[2]}\")\n",
    "print(f\"q_anc: {optimized_params[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaceab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
